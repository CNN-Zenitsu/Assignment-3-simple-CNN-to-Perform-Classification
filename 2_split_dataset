import tensorflow as tf
import matplotlib.pyplot as plt

data_dir = "/content/RealWaste"

img_height, img_width = 128*2, 128*2
batch_size = 32
seed = 123

#Split 70% train, 30% temp (val + test)
train_ds_raw = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.3,
    subset="training",
    seed=seed,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

temp_ds_raw = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.3,
    subset="validation",    # the 30% "temp" set
    seed=seed,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

class_names = train_ds_raw.class_names
num_classes = len(class_names)
print("Classes:", class_names)

#Split temp_ds into 15% validation + 15% test 
val_size = 0.5
val_ds_raw = temp_ds_raw.take(int(len(temp_ds_raw) * val_size))
test_ds_raw = temp_ds_raw.skip(int(len(temp_ds_raw) * val_size))

# Normalize and prefetch
normalization_layer = tf.keras.layers.Rescaling(1./255)

train_ds = train_ds_raw.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds_raw.map(lambda x, y: (normalization_layer(x), y))
test_ds = test_ds_raw.map(lambda x, y: (normalization_layer(x), y))

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)
val_ds = val_ds.cache().prefetch(AUTOTUNE)
test_ds = test_ds.cache().prefetch(AUTOTUNE)

print("\nâœ… Dataset Splits:")
print(f"Training batches: {len(train_ds)}")
print(f"Validation batches: {len(val_ds)}")
print(f"Testing batches: {len(test_ds)}") 


